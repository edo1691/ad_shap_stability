{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123c1709-aadd-4c93-a80a-0a0c44290983",
   "metadata": {},
   "source": [
    "# iForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2520ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e4854b-87bd-490e-88e4-9a64631dc5bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## General libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feba20a1-5d20-4127-888b-b0e4c72f4757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os.path import join\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de633751",
   "metadata": {},
   "source": [
    "### Load enviroment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a57d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "code_root = os.environ['CODE_ROOT']\n",
    "cfg_path = os.environ['CFG_PATH']\n",
    "data_root = os.environ['DATA_ROOT']\n",
    "\n",
    "sys.path.insert(0, code_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ee99b-97d7-4059-b242-380656087497",
   "metadata": {},
   "source": [
    "## Specific libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b670745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.load.functions import get_fs_dataset, fs_datasets_hyperparams\n",
    "\n",
    "from src.feature_selection.functions import shap_feature_selection, process_fi\n",
    "\n",
    "from src.utils.functions import adjust_fi\n",
    "\n",
    "from src.model.functions import run_model_experiment\n",
    "\n",
    "from src.plots.functions import plots_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db27ee-405e-4faa-a7e9-6b8cdf41d437",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a527899-7fe8-4aea-80f8-2e0447fde772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have defined the necessary functions: \n",
    "# get_fs_dataset, fs_datasets_hyperparams, shap_feature_selection, process_fi, adjust_fi, run_model_experiment\n",
    "\n",
    "# Parameters\n",
    "seed = 123\n",
    "iterations = 10\n",
    "gamma = 0.146\n",
    "n_estimators_list = [25, 50, 75, 100, 125, 150, 175, 200]\n",
    "np.random.seed(seed)\n",
    "\n",
    "# List of dataset IDs to iterate over\n",
    "dataset_ids = ['arrhythmia', 'cardio', 'bank', 'creditcard', 'mammography', 'musk']  # Add more dataset IDs as needed\n",
    "\n",
    "# Loop over each dataset\n",
    "for dataset_id in dataset_ids:\n",
    "    print(f\"Processing dataset: {dataset_id}\")\n",
    "\n",
    "    df = get_fs_dataset(dataset_id, data_root)\n",
    "    hyper = fs_datasets_hyperparams(dataset_id)\n",
    "\n",
    "    path_fi_shap = os.path.join(data_root, \"outputs\", f\"{dataset_id}_fi_shap\")\n",
    "    path_shap = os.path.join(data_root, \"outputs\", f\"{dataset_id}_shap.parquet\")\n",
    "\n",
    "    # Split the DataFrame into features (X) and target (y)\n",
    "    X = df.drop('y', axis=1)  # Features (all columns except 'y')\n",
    "    y = df['y']  # Target (the 'y' column)\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    xtr, xte, ytr, yte = train_test_split(X, y, test_size=0.1, random_state=seed)\n",
    "\n",
    "    # Initialize and train the IsolationForest model\n",
    "    model = IsolationForest(**hyper, random_state=seed)\n",
    "    model.fit(xtr)\n",
    "\n",
    "    feature_names = np.array(X.columns.tolist())\n",
    "\n",
    "    # Perform SHAP feature selection\n",
    "    selected_features_df = shap_feature_selection(model, xtr, xte, feature_names, agnostic=False)\n",
    "    fi_shap_all = process_fi(selected_features_df, 10)\n",
    "    fi_shap_all.to_parquet(path_fi_shap)\n",
    "\n",
    "    fi_shap_all = pd.read_parquet(path_fi_shap)\n",
    "    fi_shap_all = adjust_fi(fi_shap_all)\n",
    "\n",
    "    # Capture the start time\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    # Run the model experiment\n",
    "    results = run_model_experiment(fi_shap_all, df, hyper, \n",
    "                                   gamma=gamma, iterations=iterations, \n",
    "                                   n_estimators_list=n_estimators_list, seed=seed, \n",
    "                                   dataset_id=dataset_id)\n",
    "\n",
    "    # Capture the finish time\n",
    "    finish_time = datetime.datetime.now()\n",
    "\n",
    "    # Calculate the duration\n",
    "    duration = finish_time - start_time\n",
    "\n",
    "    print(f\"Duration for {dataset_id}: {duration}\")\n",
    "\n",
    "    # Save the results to a parquet file\n",
    "    results.to_parquet(path_shap)\n",
    "\n",
    "    print(f\"Completed processing for dataset: {dataset_id}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6a507-d2d7-4f34-97b3-8253c749204d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m80"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7bb90c4ec68b2a8968b0075ab0b1cb7a78770acf7a7acf2e36e903fa05bac64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
